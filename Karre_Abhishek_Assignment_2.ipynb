{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Monday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (25 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "\n",
        "(3) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(4) Collect all the information of the 904 narrators in the Densho Digital Repository.\n",
        "\n",
        "(5)**Collect a total of 10000 reviews** of the top 100 most popular software from G2 and Capterra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jDyTKYs-yGit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46df9ee-8ee0-4e0e-cf38-cab1ed2ec7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 904 narrators into Narrator_Information.csv\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "import pandas as pd\n",
        "\n",
        "# Number of pages with narrators\n",
        "total_pages = 41\n",
        "narrator_info = {}\n",
        "\n",
        "for page in range(1, total_pages + 1):\n",
        "    url = f\"https://ddr.densho.org/narrators/?page={page}\"\n",
        "    request = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    response = urlopen(request)\n",
        "    soup = BeautifulSoup(response.read(), \"html.parser\")\n",
        "\n",
        "    # Find narrator entries on the page\n",
        "    narrator_cards = soup.select(\"#list_tab .media-body\")\n",
        "\n",
        "    for card in narrator_cards:\n",
        "        if len(narrator_info) >= 904:  # stop once all narrators are collected\n",
        "            break\n",
        "        name_tag = card.find(\"a\")\n",
        "        details_tag = card.find(class_=\"source muted\")\n",
        "\n",
        "        name = name_tag.get_text(strip=True) if name_tag else \"Unknown\"\n",
        "        details = details_tag.get_text(strip=True) if details_tag else \"\"\n",
        "\n",
        "        narrator_info[name] = details\n",
        "\n",
        "    if len(narrator_info) >= 904:\n",
        "        break\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df = pd.DataFrame(list(narrator_info.items()), columns=[\"Name\", \"Details\"])\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"Narrator_Information.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\"✅ Saved {len(df)} narrators into Narrator_Information.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (15 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648dcc5a-a346-41fd-8fa3-780762c30bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Name                                            Details  \\\n",
            "0           Kay Aiko Abe  Nisei female. Born May 9, 1927, in Selleck, Wa...   \n",
            "1                Art Abe  Nisei male. Born June 12, 1921, in Seattle, Wa...   \n",
            "2  Sharon Tanagi Aburano  Nisei female. Born October 31, 1925, in Seattl...   \n",
            "3        Toshiko Aiboshi  Nisei female. Born July 8, 1928, in Boyle Heig...   \n",
            "4      Douglas L. Aihara  Sansei male. Born March 15, 1950, in Torrance,...   \n",
            "\n",
            "             CleanedName                                     CleanedDetails  \n",
            "0           kay aiko abe  nisei femal born may selleck washington spent ...  \n",
            "1                art abe  nisei male born june seattl washington grew ar...  \n",
            "2  sharon tanagi aburano  nisei femal born octob seattl washington famil...  \n",
            "3        toshiko aiboshi  nisei femal born juli boyl height california a...  \n",
            "4        dougla l aihara  sansei male born march torranc california grew...  \n"
          ]
        }
      ],
      "source": [
        "# Write code for each of the sub parts with proper comments.\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import Word\n",
        "\n",
        "df_ab = pd.read_csv(\"Narrator Information.csv\")\n",
        "df_ab = df_ab.dropna()\n",
        "\n",
        "df_ab[\"CleanedName\"] = df_ab[\"Name\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
        "df_ab[\"CleanedDetails\"] = df_ab[\"Details\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
        "\n",
        "df_ab[\"CleanedName\"] = df_ab[\"CleanedName\"].str.replace(r\"\\d+\", \"\", regex=True)\n",
        "df_ab[\"CleanedDetails\"] = df_ab[\"CleanedDetails\"].str.replace(r\"\\d+\", \"\", regex=True)\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words_ab = set(stopwords.words(\"english\"))\n",
        "\n",
        "df_ab[\"CleanedName\"] = df_ab[\"CleanedName\"].apply(\n",
        "    lambda text_ab: \" \".join(word_ab for word_ab in text_ab.split() if word_ab not in stop_words_ab)\n",
        ")\n",
        "df_ab[\"CleanedDetails\"] = df_ab[\"CleanedDetails\"].apply(\n",
        "    lambda text_ab: \" \".join(word_ab for word_ab in text_ab.split() if word_ab not in stop_words_ab)\n",
        ")\n",
        "\n",
        "df_ab[\"CleanedName\"] = df_ab[\"CleanedName\"].str.lower()\n",
        "df_ab[\"CleanedDetails\"] = df_ab[\"CleanedDetails\"].str.lower()\n",
        "\n",
        "stemmer_ab = PorterStemmer()\n",
        "\n",
        "df_ab[\"CleanedName\"] = df_ab[\"CleanedName\"].apply(\n",
        "    lambda text_ab: \" \".join(stemmer_ab.stem(word_ab) for word_ab in text_ab.split())\n",
        ")\n",
        "df_ab[\"CleanedDetails\"] = df_ab[\"CleanedDetails\"].apply(\n",
        "    lambda text_ab: \" \".join(stemmer_ab.stem(word_ab) for word_ab in text_ab.split())\n",
        ")\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "df_ab[\"CleanedName\"] = df_ab[\"CleanedName\"].apply(\n",
        "    lambda text_ab: \" \".join(Word(word_ab).lemmatize() for word_ab in text_ab.split())\n",
        ")\n",
        "df_ab[\"CleanedDetails\"] = df_ab[\"CleanedDetails\"].apply(\n",
        "    lambda text_ab: \" \".join(Word(word_ab).lemmatize() for word_ab in text_ab.split())\n",
        ")\n",
        "\n",
        "df_ab.to_csv(\"Narrators_Information_Cleaned.csv\", index=False)\n",
        "print(df_ab.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (15 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298de52c-af7f-4743-980d-f5a18181d2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Nouns: 8890\n",
            "Total Verbs: 2058\n",
            "Total Adjectives: 2737\n",
            "Total Adverbs: 464\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "def ensure_nltk_ready():\n",
        "    try:\n",
        "        nltk.data.find(\"taggers/averaged_perceptron_tagger\")\n",
        "    except LookupError:\n",
        "        nltk.download(\"averaged_perceptron_tagger\")\n",
        "    # NLTK ≥ 3.9 may require the *_eng variant\n",
        "    try:\n",
        "        nltk.data.find(\"taggers/averaged_perceptron_tagger_eng\")\n",
        "    except LookupError:\n",
        "        try:\n",
        "            nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "ensure_nltk_ready()\n",
        "\n",
        "# Load cleaned narrators CSV\n",
        "narrators_df = pd.read_csv(\"/content/Narrators_Information_Cleaned.csv\")\n",
        "\n",
        "# Use whichever cleaned-details column exists\n",
        "details_col = \"CleanedDetails_ab\" if \"CleanedDetails_ab\" in narrators_df.columns else \"CleanedDetails\"\n",
        "if details_col not in narrators_df.columns:\n",
        "    raise KeyError(\"Expected 'CleanedDetails' or 'CleanedDetails_ab' in the CSV.\")\n",
        "narrators_df[details_col] = narrators_df[details_col].fillna(\"\")\n",
        "\n",
        "# Function to count POS categories (preserve_line avoids punkt/punkt_tab)\n",
        "def extract_pos_counts(text):\n",
        "    tokens = word_tokenize(str(text), preserve_line=True)\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    tag_counts = Counter(tag for _, tag in tagged_tokens)\n",
        "\n",
        "    noun_count = sum(tag_counts.get(tag, 0) for tag in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"])\n",
        "    verb_count = sum(tag_counts.get(tag, 0) for tag in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"])\n",
        "    adjective_count = sum(tag_counts.get(tag, 0) for tag in [\"JJ\", \"JJR\", \"JJS\"])\n",
        "    adverb_count = sum(tag_counts.get(tag, 0) for tag in [\"RB\", \"RBR\", \"RBS\"])\n",
        "\n",
        "    return noun_count, verb_count, adjective_count, adverb_count\n",
        "\n",
        "# Apply POS tagging on the cleaned details column\n",
        "narrators_df[[\"NounCount\", \"VerbCount\", \"AdjectiveCount\", \"AdverbCount\"]] = pd.DataFrame(\n",
        "    narrators_df[details_col].apply(extract_pos_counts).to_list(),\n",
        "    index=narrators_df.index\n",
        ")\n",
        "\n",
        "# Compute totals across dataset\n",
        "total_nouns = int(narrators_df[\"NounCount\"].sum())\n",
        "total_verbs = int(narrators_df[\"VerbCount\"].sum())\n",
        "total_adjectives = int(narrators_df[\"AdjectiveCount\"].sum())\n",
        "total_adverbs = int(narrators_df[\"AdverbCount\"].sum())\n",
        "\n",
        "print(f\"Total Nouns: {total_nouns}\")\n",
        "print(f\"Total Verbs: {total_verbs}\")\n",
        "print(f\"Total Adjectives: {total_adjectives}\")\n",
        "print(f\"Total Adverbs: {total_adverbs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install benepar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb8xMFprmL5Z",
        "outputId": "c042d611-3761-4b4f-9cbc-67682bf09ecb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting benepar\n",
            "  Downloading benepar-0.2.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.12/dist-packages (from benepar) (3.9.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.12/dist-packages (from benepar) (3.8.7)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from benepar) (2.8.0+cu126)\n",
            "Collecting torch-struct>=0.5 (from benepar)\n",
            "  Downloading torch_struct-0.5-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.12/dist-packages (from benepar) (0.22.0)\n",
            "Requirement already satisfied: transformers>=4.2.2 in /usr/local/lib/python3.12/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (4.56.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from benepar) (5.29.5)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from benepar) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2->benepar) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2->benepar) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2->benepar) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2->benepar) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (0.17.4)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (2.11.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=2.0.9->benepar) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.9.4->benepar) (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->benepar) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (0.6.2)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (1.10.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.9.4->benepar) (1.1.10)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->benepar) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.9->benepar) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy>=2.0.9->benepar) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (0.1.2)\n",
            "Downloading torch_struct-0.5-py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.2.0-py3-none-any.whl size=37625 sha256=4e731471c13d1fbab1791405629e556294b21f3cd750dd1449f5a9ed9f69c4b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/84/c1/f2ac877f519e2864e7dfe52a1c17fe5cdd50819cb8d1f1945f\n",
            "Successfully built benepar\n",
            "Installing collected packages: torch-struct, benepar\n",
            "Successfully installed benepar-0.2.0 torch-struct-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import benepar\n",
        "from spacy import displacy\n",
        "from nltk import Tree\n",
        "\n",
        "# Load spaCy model and benepar\n",
        "nlp_ab = spacy.load(\"en_core_web_sm\")\n",
        "benepar.download(\"benepar_en3\")\n",
        "nlp_ab.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
        "\n",
        "def plot_dependency_tree_ab(doc_ab):\n",
        "    print(\"\\nDependency Parsing Tree (Text Representation):\")\n",
        "    for token_ab in doc_ab:\n",
        "        print(f\"{token_ab.text} --({token_ab.dep_} → {spacy.explain(token_ab.dep_)})--> {token_ab.head.text}\")\n",
        "    displacy.render(doc_ab, style=\"dep\", jupyter=True, options={\"compact\": True, \"distance\": 90})\n",
        "\n",
        "def plot_constituency_tree_ab(doc_ab):\n",
        "    for sent_ab in doc_ab.sents:\n",
        "        print(\"\\nConstituency Parsing Tree (Text Representation):\")\n",
        "        print(sent_ab._.parse_string)\n",
        "        tree_ab = Tree.fromstring(sent_ab._.parse_string)\n",
        "        tree_ab.pretty_print()\n",
        "\n",
        "# Example: take first cleaned detail from your dataframe\n",
        "sentence_ab = df_pos_ab[\"CleanedDetails\"][0]\n",
        "doc_ab = nlp_ab(sentence_ab)\n",
        "\n",
        "print(f\"Sentence: {sentence_ab}\")\n",
        "\n",
        "plot_dependency_tree_ab(doc_ab)\n",
        "plot_constituency_tree_ab(doc_ab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wpkSad_emBpi",
        "outputId": "4a2a39e0-ff3c-4d06-f7d8-53104253094e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/benepar_en3.zip.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: nisei femal born may selleck washington spent much childhood beaverton oregon father own farm influenc earli\n",
            "\n",
            "Dependency Parsing Tree (Text Representation):\n",
            "nisei --(compound → compound)--> femal\n",
            "femal --(nsubj → nominal subject)--> spent\n",
            "born --(acl → clausal modifier of noun (adjectival clause))--> femal\n",
            "may --(aux → auxiliary)--> spent\n",
            "selleck --(compound → compound)--> washington\n",
            "washington --(nsubj → nominal subject)--> spent\n",
            "spent --(ROOT → root)--> spent\n",
            "much --(amod → adjectival modifier)--> beaverton\n",
            "childhood --(compound → compound)--> beaverton\n",
            "beaverton --(compound → compound)--> father\n",
            "oregon --(compound → compound)--> father\n",
            "father --(compound → compound)--> earli\n",
            "own --(amod → adjectival modifier)--> earli\n",
            "farm --(compound → compound)--> influenc\n",
            "influenc --(compound → compound)--> earli\n",
            "earli --(dobj → direct object)--> spent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/distributions/distribution.py:62: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"081b6a6cef9548aaaaf3c524fe8681a5-0\" class=\"displacy\" width=\"1490\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">nisei</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">femal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">born</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">may</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">selleck</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">washington</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">spent</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">much</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">childhood</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">beaverton</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">oregon</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">father</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">own</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">farm</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">influenc</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">earli</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-0\" stroke-width=\"2px\" d=\"M62,182.0 62,167.0 131.0,167.0 131.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M62,184.0 L58,176.0 66,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-1\" stroke-width=\"2px\" d=\"M152,182.0 152,137.0 587.0,137.0 587.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M152,184.0 L148,176.0 156,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-2\" stroke-width=\"2px\" d=\"M152,182.0 152,167.0 221.0,167.0 221.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M221.0,184.0 L225.0,176.0 217.0,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-3\" stroke-width=\"2px\" d=\"M332,182.0 332,152.0 584.0,152.0 584.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M332,184.0 L328,176.0 336,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-4\" stroke-width=\"2px\" d=\"M422,182.0 422,167.0 491.0,167.0 491.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M422,184.0 L418,176.0 426,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-5\" stroke-width=\"2px\" d=\"M512,182.0 512,167.0 581.0,167.0 581.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M512,184.0 L508,176.0 516,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-6\" stroke-width=\"2px\" d=\"M692,182.0 692,152.0 854.0,152.0 854.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M692,184.0 L688,176.0 696,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-7\" stroke-width=\"2px\" d=\"M782,182.0 782,167.0 851.0,167.0 851.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M782,184.0 L778,176.0 786,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-8\" stroke-width=\"2px\" d=\"M872,182.0 872,152.0 1034.0,152.0 1034.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M872,184.0 L868,176.0 876,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-9\" stroke-width=\"2px\" d=\"M962,182.0 962,167.0 1031.0,167.0 1031.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M962,184.0 L958,176.0 966,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-10\" stroke-width=\"2px\" d=\"M1052,182.0 1052,137.0 1397.0,137.0 1397.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1052,184.0 L1048,176.0 1056,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-11\" stroke-width=\"2px\" d=\"M1142,182.0 1142,152.0 1394.0,152.0 1394.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1142,184.0 L1138,176.0 1146,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-12\" stroke-width=\"2px\" d=\"M1232,182.0 1232,167.0 1301.0,167.0 1301.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1232,184.0 L1228,176.0 1236,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-13\" stroke-width=\"2px\" d=\"M1322,182.0 1322,167.0 1391.0,167.0 1391.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1322,184.0 L1318,176.0 1326,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-14\" stroke-width=\"2px\" d=\"M602,182.0 602,122.0 1400.0,122.0 1400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-081b6a6cef9548aaaaf3c524fe8681a5-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1400.0,184.0 L1404.0,176.0 1396.0,176.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Constituency Parsing Tree (Text Representation):\n",
            "(S (NP (NP (FW nisei) (NN femal)) (VP (VP (VBN born) (MD may) (RB selleck)) (NNP washington))) (VP (VBD spent) (NP (JJ much) (NN childhood)) (NP (NP (UCP (NN beaverton) (FW oregon)) (NN father)) (JJ own) (NN farm) (FW influenc) (FW earli))))\n",
            "                                                       S                                                                    \n",
            "                  _____________________________________|_________________________________                                    \n",
            "                 |                                                                       VP                                 \n",
            "                 |                                 ______________________________________|____________                       \n",
            "                 NP                               |         |                                         NP                    \n",
            "        _________|________                        |         |                             ____________|__________________    \n",
            "       |                  VP                      |         |                            NP           |   |      |       |  \n",
            "       |               ___|______________         |         |                        ____|______      |   |      |       |   \n",
            "       NP             VP                 |        |         NP                     UCP          |     |   |      |       |  \n",
            "   ____|____      ____|_________         |        |     ____|______           ______|____       |     |   |      |       |   \n",
            "  FW        NN  VBN   MD        RB      NNP      VBD   JJ          NN        NN          FW     NN    JJ  NN     FW      FW \n",
            "  |         |    |    |         |        |        |    |           |         |           |      |     |   |      |       |   \n",
            "nisei     femal born may     selleck washington spent much     childhood beaverton     oregon father own farm influenc earli\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Load a small English model from spaCy\n",
        "nlp_ab = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Read the preprocessed narrator information\n",
        "df_ner_ab = pd.read_csv(\"/content/Narrators_Information_Cleaned.csv\")\n",
        "\n",
        "# Create a counter for entity frequencies and a dictionary for storing sample entities\n",
        "entity_counter_ab = Counter()\n",
        "entity_examples_ab = {\"PERSON\": [], \"ORG\": [], \"GPE\": [], \"PRODUCT\": [], \"DATE\": []}\n",
        "\n",
        "# Loop through each record in the CleanedDetails column and perform NER\n",
        "for detail_ab in df_ner_ab[\"CleanedDetails\"]:\n",
        "    doc_ab = nlp_ab(str(detail_ab))\n",
        "    for ent_ab in doc_ab.ents:\n",
        "        if ent_ab.label_ in entity_examples_ab:\n",
        "            entity_counter_ab[ent_ab.label_] += 1\n",
        "            # entity_examples_ab[ent_ab.label_].append(ent_ab.text)  # optional storage\n",
        "\n",
        "# Display the overall counts of recognized entity types\n",
        "print(\"Named Entity Recognition Results:\")\n",
        "for entity_ab, count_ab in entity_counter_ab.items():\n",
        "    print(f\"{entity_ab}: {count_ab} Entities\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1vPeXd9meJg",
        "outputId": "28dd8379-317d-43e7-ecb9-d0f3413f497a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition Results:\n",
            "PERSON: 1200 Entities\n",
            "GPE: 1402 Entities\n",
            "DATE: 228 Entities\n",
            "ORG: 205 Entities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Following Questions must answer using AI assitance**"
      ],
      "metadata": {
        "id": "EcVqy1yj3wja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4 (20 points)."
      ],
      "metadata": {
        "id": "kEdcyHX8VaDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. (PART-1)\n",
        "Web scraping data from the GitHub Marketplace to gather details about popular actions. Using Python, the process begins by sending HTTP requests to multiple pages of the marketplace (1000 products), handling pagination through dynamic page numbers. The key details extracted include the product name, a short description, and the URL.\n",
        "\n",
        " The extracted data is stored in a structured CSV format with columns for product name, description, URL, and page number. A time delay is introduced between requests to avoid server overload. ChatGPT can assist by helping with the parsing of HTML, error handling, and generating reports based on the data collected.\n",
        "\n",
        " The goal is to complete the scraping within a specified time limit, ensuring that the process is efficient and adheres to GitHub’s usage guidelines.\n",
        "\n",
        "(PART -2)\n",
        "\n",
        "1.   **Preprocess Data**: Clean the text by tokenizing, removing stopwords, and converting to lowercase.\n",
        "\n",
        "2. Perform **Data Quality** operations.\n",
        "\n",
        "\n",
        "Preprocessing:\n",
        "Preprocessing involves cleaning the text by removing noise such as special characters, HTML tags, and unnecessary whitespace. It also includes tasks like tokenization, stopword removal, and lemmatization to standardize the text for analysis.\n",
        "\n",
        "Data Quality:\n",
        "Data quality checks ensure completeness, consistency, and accuracy by verifying that all required columns are filled and formatted correctly. Additionally, it involves identifying and removing duplicates, handling missing values, and ensuring the data reflects the true content accurately.\n"
      ],
      "metadata": {
        "id": "1Ung5_YW3C6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github MarketPlace page:\n",
        "https://github.com/marketplace?type=actions"
      ],
      "metadata": {
        "id": "CTOfUpatronW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, time, random, re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "BASE_ab = \"https://github.com\"\n",
        "INDEX_ab = BASE_ab + \"/marketplace?type=actions&page={}&sort=popularity\"\n",
        "HEADERS_ab = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\"\n",
        "}\n",
        "\n",
        "rows_ab = []\n",
        "seen_ab = set()\n",
        "max_pages_ab = 600\n",
        "target_min_ab = 1000\n",
        "consec_empty_ab = 0\n",
        "\n",
        "for page_ab in range(1, max_pages_ab + 1):\n",
        "    url_ab = INDEX_ab.format(page_ab)\n",
        "    r_ab = requests.get(url_ab, headers=HEADERS_ab, timeout=30)\n",
        "    if r_ab.status_code != 200:\n",
        "        print(f\"⚠️ Page {page_ab} status {r_ab.status_code}; stopping.\")\n",
        "        break\n",
        "\n",
        "    soup_ab = BeautifulSoup(r_ab.text, \"html.parser\")\n",
        "    links_ab = soup_ab.select('a[href^=\"/marketplace/actions/\"]')\n",
        "\n",
        "    hrefs_ab = []\n",
        "    for a_ab in links_ab:\n",
        "        href_ab = a_ab.get(\"href\", \"\")\n",
        "        if re.fullmatch(r\"/marketplace/actions/[a-zA-Z0-9\\-._]+\", href_ab):\n",
        "            hrefs_ab.append(href_ab)\n",
        "    hrefs_ab = list(dict.fromkeys(hrefs_ab))\n",
        "\n",
        "    added_this_page_ab = 0\n",
        "    for href_ab in hrefs_ab:\n",
        "        full_ab = BASE_ab + href_ab\n",
        "        if full_ab in seen_ab:\n",
        "            continue\n",
        "        a_ab = soup_ab.find(\"a\", href=href_ab)\n",
        "        title_ab = a_ab.get_text(strip=True) if a_ab else \"\"\n",
        "        desc_ab = \"\"\n",
        "        if a_ab:\n",
        "            h3_ab = a_ab.find_parent(\"h3\")\n",
        "            if h3_ab:\n",
        "                sib_p_ab = h3_ab.find_next_sibling(\"p\")\n",
        "                if sib_p_ab:\n",
        "                    desc_ab = sib_p_ab.get_text(\" \", strip=True)\n",
        "                else:\n",
        "                    p_ab = h3_ab.find_next(\"p\")\n",
        "                    if p_ab:\n",
        "                        desc_ab = p_ab.get_text(\" \", strip=True)\n",
        "\n",
        "        rows_ab.append(\n",
        "            {\n",
        "                \"Product Name\": title_ab or \"N/A\",\n",
        "                \"Description\": desc_ab or \"N/A\",\n",
        "                \"URL\": full_ab,\n",
        "                \"Page\": page_ab,\n",
        "            }\n",
        "        )\n",
        "        seen_ab.add(full_ab)\n",
        "        added_this_page_ab += 1\n",
        "\n",
        "    if added_this_page_ab == 0:\n",
        "        consec_empty_ab += 1\n",
        "    else:\n",
        "        consec_empty_ab = 0\n",
        "\n",
        "    print(f\" Page {page_ab}: {added_this_page_ab} items (total {len(seen_ab)})\")\n",
        "    time.sleep(random.uniform(1.2, 2.5))\n",
        "\n",
        "    if len(seen_ab) >= target_min_ab and page_ab >= 1:\n",
        "        print(\" Reached target minimum items.\")\n",
        "        break\n",
        "    if consec_empty_ab >= 2:\n",
        "        print(\" Two consecutive empty pages; stopping.\")\n",
        "        break\n",
        "\n",
        "df_git_ab = pd.DataFrame(rows_ab).drop_duplicates(subset=[\"URL\"]).reset_index(drop=True)\n",
        "df_git_ab.to_csv(\"GitHub_Actions.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\" Saved {len(df_git_ab)} products to GitHub_Actions.csv\")\n",
        "display(df_git_ab.head(10))\n"
      ],
      "metadata": {
        "id": "4dtco9K--ks6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a45a39c-656b-4833-af35-79833af4a765"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Page 1: 20 items (total 20)\n",
            " Page 2: 20 items (total 40)\n",
            " Page 3: 20 items (total 60)\n",
            " Page 4: 0 items (total 60)\n",
            " Page 5: 20 items (total 80)\n",
            " Page 6: 20 items (total 100)\n",
            " Page 7: 0 items (total 100)\n",
            " Page 8: 20 items (total 120)\n",
            " Page 9: 20 items (total 140)\n",
            " Page 10: 20 items (total 160)\n",
            " Page 11: 0 items (total 160)\n",
            " Page 12: 20 items (total 180)\n",
            " Page 13: 20 items (total 200)\n",
            " Page 14: 0 items (total 200)\n",
            " Page 15: 20 items (total 220)\n",
            " Page 16: 20 items (total 240)\n",
            " Page 17: 20 items (total 260)\n",
            " Page 18: 0 items (total 260)\n",
            " Page 19: 20 items (total 280)\n",
            " Page 20: 20 items (total 300)\n",
            " Page 21: 20 items (total 320)\n",
            " Page 22: 20 items (total 340)\n",
            " Page 23: 19 items (total 359)\n",
            " Page 24: 20 items (total 379)\n",
            " Page 25: 20 items (total 399)\n",
            " Page 26: 20 items (total 419)\n",
            " Page 27: 20 items (total 439)\n",
            " Page 28: 20 items (total 459)\n",
            " Page 29: 20 items (total 479)\n",
            " Page 30: 20 items (total 499)\n",
            " Page 31: 20 items (total 519)\n",
            " Page 32: 20 items (total 539)\n",
            " Page 33: 20 items (total 559)\n",
            " Page 34: 20 items (total 579)\n",
            " Page 35: 20 items (total 599)\n",
            " Page 36: 20 items (total 619)\n",
            " Page 37: 20 items (total 639)\n",
            " Page 38: 18 items (total 657)\n",
            " Page 39: 20 items (total 677)\n",
            " Page 40: 20 items (total 697)\n",
            " Page 41: 20 items (total 717)\n",
            " Page 42: 20 items (total 737)\n",
            " Page 43: 20 items (total 757)\n",
            " Page 44: 20 items (total 777)\n",
            " Page 45: 20 items (total 797)\n",
            " Page 46: 19 items (total 816)\n",
            " Page 47: 19 items (total 835)\n",
            " Page 48: 20 items (total 855)\n",
            " Page 49: 19 items (total 874)\n",
            " Page 50: 20 items (total 894)\n",
            " Page 51: 0 items (total 894)\n",
            " Page 52: 20 items (total 914)\n",
            " Page 53: 20 items (total 934)\n",
            " Page 54: 20 items (total 954)\n",
            " Page 55: 20 items (total 974)\n",
            " Page 56: 20 items (total 994)\n",
            " Page 57: 20 items (total 1014)\n",
            " Reached target minimum items.\n",
            " Saved 1014 products to GitHub_Actions.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                        Product Name  \\\n",
              "0                                     TruffleHog OSS   \n",
              "1                                      Metrics embed   \n",
              "2                       yq - portable yaml processor   \n",
              "3                                       Super-Linter   \n",
              "4                             Gosec Security Checker   \n",
              "5                         Rebuild Armbian and Kernel   \n",
              "6                                           Checkout   \n",
              "7             OpenCommit — improve commits with AI 🧙   \n",
              "8                                SSH Remote Commands   \n",
              "9  generate-snake-game-from-github-contribution-grid   \n",
              "\n",
              "                                         Description  \\\n",
              "0  Find and verify leaked credentials in your sou...   \n",
              "1  An infographics generator with 40+ plugins and...   \n",
              "2  create, read, update, delete, merge, validate ...   \n",
              "3  Super-linter is a ready-to-run collection of l...   \n",
              "4                    Runs the gosec security checker   \n",
              "5      Support Amlogic, Rockchip and Allwinner boxes   \n",
              "6  Checkout a Git repository at a particular version   \n",
              "7  Replaces lame commit messages with meaningful ...   \n",
              "8                      Executing remote ssh commands   \n",
              "9  Generates a snake game from a github user cont...   \n",
              "\n",
              "                                                 URL  Page  \n",
              "0  https://github.com/marketplace/actions/truffle...     1  \n",
              "1  https://github.com/marketplace/actions/metrics...     1  \n",
              "2  https://github.com/marketplace/actions/yq-port...     1  \n",
              "3  https://github.com/marketplace/actions/super-l...     1  \n",
              "4  https://github.com/marketplace/actions/gosec-s...     1  \n",
              "5  https://github.com/marketplace/actions/rebuild...     1  \n",
              "6    https://github.com/marketplace/actions/checkout     1  \n",
              "7  https://github.com/marketplace/actions/opencom...     1  \n",
              "8  https://github.com/marketplace/actions/ssh-rem...     1  \n",
              "9  https://github.com/marketplace/actions/generat...     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68b796cd-c5d3-435e-9993-1cef97306f69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "      <th>Page</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TruffleHog OSS</td>\n",
              "      <td>Find and verify leaked credentials in your sou...</td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Metrics embed</td>\n",
              "      <td>An infographics generator with 40+ plugins and...</td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq - portable yaml processor</td>\n",
              "      <td>create, read, update, delete, merge, validate ...</td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super-Linter</td>\n",
              "      <td>Super-linter is a ready-to-run collection of l...</td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gosec Security Checker</td>\n",
              "      <td>Runs the gosec security checker</td>\n",
              "      <td>https://github.com/marketplace/actions/gosec-s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rebuild Armbian and Kernel</td>\n",
              "      <td>Support Amlogic, Rockchip and Allwinner boxes</td>\n",
              "      <td>https://github.com/marketplace/actions/rebuild...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Checkout</td>\n",
              "      <td>Checkout a Git repository at a particular version</td>\n",
              "      <td>https://github.com/marketplace/actions/checkout</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OpenCommit — improve commits with AI 🧙</td>\n",
              "      <td>Replaces lame commit messages with meaningful ...</td>\n",
              "      <td>https://github.com/marketplace/actions/opencom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SSH Remote Commands</td>\n",
              "      <td>Executing remote ssh commands</td>\n",
              "      <td>https://github.com/marketplace/actions/ssh-rem...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>generate-snake-game-from-github-contribution-grid</td>\n",
              "      <td>Generates a snake game from a github user cont...</td>\n",
              "      <td>https://github.com/marketplace/actions/generat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68b796cd-c5d3-435e-9993-1cef97306f69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68b796cd-c5d3-435e-9993-1cef97306f69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68b796cd-c5d3-435e-9993-1cef97306f69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f0309d1-b643-41ff-8131-6cf19265daa9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f0309d1-b643-41ff-8131-6cf19265daa9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f0309d1-b643-41ff-8131-6cf19265daa9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_git_ab\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Product Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SSH Remote Commands\",\n          \"Metrics embed\",\n          \"Rebuild Armbian and Kernel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Executing remote ssh commands\",\n          \"An infographics generator with 40+ plugins and 300+ options to display stats about your GitHub account\",\n          \"Support Amlogic, Rockchip and Allwinner boxes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/ssh-remote-commands\",\n          \"https://github.com/marketplace/actions/metrics-embed\",\n          \"https://github.com/marketplace/actions/rebuild-armbian-and-kernel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Page\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk, re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"wordnet\", quiet=True)\n",
        "\n",
        "INPUT_CSV_ab = \"GitHub_Actions.csv\"\n",
        "df_ab = pd.read_csv(INPUT_CSV_ab)\n",
        "\n",
        "print(f\"Loaded {len(df_ab)} rows from {INPUT_CSV_ab}\")\n",
        "\n",
        "df_ab = df_ab.fillna(\"\")\n",
        "for c_ab in [\"Product Name\", \"Description\", \"URL\"]:\n",
        "    df_ab[c_ab] = df_ab[c_ab].astype(str).str.strip()\n",
        "\n",
        "before_dedup_ab = len(df_ab)\n",
        "df_ab = df_ab.drop_duplicates(subset=[\"URL\"]).reset_index(drop=True)\n",
        "print(f\"Deduplicated by URL: {before_dedup_ab} -> {len(df_ab)}\")\n",
        "\n",
        "stop_words_ab = set(stopwords.words(\"english\"))\n",
        "lemm_ab = WordNetLemmatizer()\n",
        "\n",
        "def clean_text_ab(text_ab: str) -> str:\n",
        "    text_ab = re.sub(r\"<.*?>\", \" \", text_ab)\n",
        "    text_ab = re.sub(r\"&[a-z]+;\", \" \", text_ab)\n",
        "    text_ab = re.sub(r\"[^a-zA-Z\\s]\", \" \", text_ab)\n",
        "    text_ab = re.sub(r\"\\s+\", \" \", text_ab).strip().lower()\n",
        "    toks_ab = nltk.word_tokenize(text_ab)\n",
        "    toks_ab = [t_ab for t_ab in toks_ab if t_ab not in stop_words_ab]\n",
        "    toks_ab = [lemm_ab.lemmatize(t_ab) for t_ab in toks_ab]\n",
        "    return \" \".join(toks_ab)\n",
        "\n",
        "df_ab[\"Cleaned_Name\"] = df_ab[\"Product Name\"].map(clean_text_ab)\n",
        "df_ab[\"Cleaned_Description\"] = df_ab[\"Description\"].map(clean_text_ab)\n",
        "\n",
        "df_ab[\"Valid_URL\"] = df_ab[\"URL\"].str.contains(\n",
        "    r\"^https://github\\.com/marketplace/actions/.*\", regex=True, na=False\n",
        ")\n",
        "\n",
        "df_ab[\"Missing_Desc\"] = df_ab[\"Description\"].eq(\"\") | (df_ab[\"Description\"].str.len() < 3) | df_ab[\"Description\"].eq(\"N/A\")\n",
        "\n",
        "n_urls_invalid_ab = (~df_ab[\"Valid_URL\"]).sum()\n",
        "n_missing_desc_ab = df_ab[\"Missing_Desc\"].sum()\n",
        "print(f\"Invalid URL pattern: {n_urls_invalid_ab} rows\")\n",
        "print(f\"Missing/weak descriptions: {n_missing_desc_ab} rows\")\n",
        "\n",
        "FULL_OUT_ab = \"GitHub_Actions_Cleaned.csv\"\n",
        "df_ab.to_csv(FULL_OUT_ab, index=False, encoding=\"utf-8\")\n",
        "print(f\" Saved full cleaned data with flags to {FULL_OUT_ab} (rows: {len(df_ab)})\")\n",
        "\n",
        "subset_ab = df_ab[df_ab[\"Valid_URL\"]].reset_index(drop=True)\n",
        "SUB_OUT_ab = \"GitHub_Actions_Cleaned_ValidOnly.csv\"\n",
        "subset_ab.to_csv(SUB_OUT_ab, index=False, encoding=\"utf-8\")\n",
        "print(f\" Saved valid-URL subset to {SUB_OUT_ab} (rows: {len(subset_ab)})\")\n",
        "\n",
        "display(df_ab.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ApAQl_hxxAsy",
        "outputId": "04b419c7-1799-424b-d536-d855c5fc6b53"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1014 rows from GitHub_Actions.csv\n",
            "Deduplicated by URL: 1014 -> 1014\n",
            "Invalid URL pattern: 0 rows\n",
            "Missing/weak descriptions: 0 rows\n",
            " Saved full cleaned data with flags to GitHub_Actions_Cleaned.csv (rows: 1014)\n",
            " Saved valid-URL subset to GitHub_Actions_Cleaned_ValidOnly.csv (rows: 1014)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                        Product Name  \\\n",
              "0                                     TruffleHog OSS   \n",
              "1                                      Metrics embed   \n",
              "2                       yq - portable yaml processor   \n",
              "3                                       Super-Linter   \n",
              "4                             Gosec Security Checker   \n",
              "5                         Rebuild Armbian and Kernel   \n",
              "6                                           Checkout   \n",
              "7             OpenCommit — improve commits with AI 🧙   \n",
              "8                                SSH Remote Commands   \n",
              "9  generate-snake-game-from-github-contribution-grid   \n",
              "\n",
              "                                         Description  \\\n",
              "0  Find and verify leaked credentials in your sou...   \n",
              "1  An infographics generator with 40+ plugins and...   \n",
              "2  create, read, update, delete, merge, validate ...   \n",
              "3  Super-linter is a ready-to-run collection of l...   \n",
              "4                    Runs the gosec security checker   \n",
              "5      Support Amlogic, Rockchip and Allwinner boxes   \n",
              "6  Checkout a Git repository at a particular version   \n",
              "7  Replaces lame commit messages with meaningful ...   \n",
              "8                      Executing remote ssh commands   \n",
              "9  Generates a snake game from a github user cont...   \n",
              "\n",
              "                                                 URL  Page  \\\n",
              "0  https://github.com/marketplace/actions/truffle...     1   \n",
              "1  https://github.com/marketplace/actions/metrics...     1   \n",
              "2  https://github.com/marketplace/actions/yq-port...     1   \n",
              "3  https://github.com/marketplace/actions/super-l...     1   \n",
              "4  https://github.com/marketplace/actions/gosec-s...     1   \n",
              "5  https://github.com/marketplace/actions/rebuild...     1   \n",
              "6    https://github.com/marketplace/actions/checkout     1   \n",
              "7  https://github.com/marketplace/actions/opencom...     1   \n",
              "8  https://github.com/marketplace/actions/ssh-rem...     1   \n",
              "9  https://github.com/marketplace/actions/generat...     1   \n",
              "\n",
              "                                   Cleaned_Name  \\\n",
              "0                                 trufflehog os   \n",
              "1                                  metric embed   \n",
              "2                    yq portable yaml processor   \n",
              "3                                  super linter   \n",
              "4                        gosec security checker   \n",
              "5                        rebuild armbian kernel   \n",
              "6                                      checkout   \n",
              "7                 opencommit improve commits ai   \n",
              "8                            ssh remote command   \n",
              "9  generate snake game github contribution grid   \n",
              "\n",
              "                                 Cleaned_Description  Valid_URL  Missing_Desc  \n",
              "0          find verify leaked credential source code       True         False  \n",
              "1  infographics generator plugins option display ...       True         False  \n",
              "2      create read update delete merge validate yaml       True         False  \n",
              "3  super linter ready run collection linters code...       True         False  \n",
              "4                         run gosec security checker       True         False  \n",
              "5             support amlogic rockchip allwinner box       True         False  \n",
              "6         checkout git repository particular version       True         False  \n",
              "7  replaces lame commit message meaningful ai gen...       True         False  \n",
              "8                       executing remote ssh command       True         False  \n",
              "9  generates snake game github user contribution ...       True         False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61512986-f0f7-425a-adb7-980cfcac1934\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "      <th>Page</th>\n",
              "      <th>Cleaned_Name</th>\n",
              "      <th>Cleaned_Description</th>\n",
              "      <th>Valid_URL</th>\n",
              "      <th>Missing_Desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TruffleHog OSS</td>\n",
              "      <td>Find and verify leaked credentials in your sou...</td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "      <td>trufflehog os</td>\n",
              "      <td>find verify leaked credential source code</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Metrics embed</td>\n",
              "      <td>An infographics generator with 40+ plugins and...</td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "      <td>metric embed</td>\n",
              "      <td>infographics generator plugins option display ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq - portable yaml processor</td>\n",
              "      <td>create, read, update, delete, merge, validate ...</td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "      <td>yq portable yaml processor</td>\n",
              "      <td>create read update delete merge validate yaml</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super-Linter</td>\n",
              "      <td>Super-linter is a ready-to-run collection of l...</td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "      <td>super linter</td>\n",
              "      <td>super linter ready run collection linters code...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gosec Security Checker</td>\n",
              "      <td>Runs the gosec security checker</td>\n",
              "      <td>https://github.com/marketplace/actions/gosec-s...</td>\n",
              "      <td>1</td>\n",
              "      <td>gosec security checker</td>\n",
              "      <td>run gosec security checker</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rebuild Armbian and Kernel</td>\n",
              "      <td>Support Amlogic, Rockchip and Allwinner boxes</td>\n",
              "      <td>https://github.com/marketplace/actions/rebuild...</td>\n",
              "      <td>1</td>\n",
              "      <td>rebuild armbian kernel</td>\n",
              "      <td>support amlogic rockchip allwinner box</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Checkout</td>\n",
              "      <td>Checkout a Git repository at a particular version</td>\n",
              "      <td>https://github.com/marketplace/actions/checkout</td>\n",
              "      <td>1</td>\n",
              "      <td>checkout</td>\n",
              "      <td>checkout git repository particular version</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OpenCommit — improve commits with AI 🧙</td>\n",
              "      <td>Replaces lame commit messages with meaningful ...</td>\n",
              "      <td>https://github.com/marketplace/actions/opencom...</td>\n",
              "      <td>1</td>\n",
              "      <td>opencommit improve commits ai</td>\n",
              "      <td>replaces lame commit message meaningful ai gen...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SSH Remote Commands</td>\n",
              "      <td>Executing remote ssh commands</td>\n",
              "      <td>https://github.com/marketplace/actions/ssh-rem...</td>\n",
              "      <td>1</td>\n",
              "      <td>ssh remote command</td>\n",
              "      <td>executing remote ssh command</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>generate-snake-game-from-github-contribution-grid</td>\n",
              "      <td>Generates a snake game from a github user cont...</td>\n",
              "      <td>https://github.com/marketplace/actions/generat...</td>\n",
              "      <td>1</td>\n",
              "      <td>generate snake game github contribution grid</td>\n",
              "      <td>generates snake game github user contribution ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61512986-f0f7-425a-adb7-980cfcac1934')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61512986-f0f7-425a-adb7-980cfcac1934 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61512986-f0f7-425a-adb7-980cfcac1934');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8dcc8eb7-a22e-4ddc-b020-0f587d6e2669\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dcc8eb7-a22e-4ddc-b020-0f587d6e2669')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8dcc8eb7-a22e-4ddc-b020-0f587d6e2669 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_ab\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Product Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SSH Remote Commands\",\n          \"Metrics embed\",\n          \"Rebuild Armbian and Kernel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Executing remote ssh commands\",\n          \"An infographics generator with 40+ plugins and 300+ options to display stats about your GitHub account\",\n          \"Support Amlogic, Rockchip and Allwinner boxes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/ssh-remote-commands\",\n          \"https://github.com/marketplace/actions/metrics-embed\",\n          \"https://github.com/marketplace/actions/rebuild-armbian-and-kernel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Page\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ssh remote command\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"executing remote ssh command\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid_URL\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Missing_Desc\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5 (20 points)\n",
        "\n",
        "PART 1:\n",
        "Web Scrape  tweets from Twitter using the Tweepy API, specifically targeting hashtags related to subtopics (machine learning or artificial intelligence.)\n",
        "The extracted data includes the tweet ID, username, and text.\n",
        "\n",
        "Part 2:\n",
        "Perform data cleaning procedures\n",
        "\n",
        "A final data quality check ensures the completeness and consistency of the dataset. The cleaned data is then saved into a CSV file for further analysis.\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1.   Follow tutorials provided in canvas to obtain api keys. Use ChatGPT to get the code. Make sure the file is downloaded and saved.\n",
        "2.   Make sure you divide GPT code as shown in tutorials, dont make multiple requestes.\n"
      ],
      "metadata": {
        "id": "3WeD70ty3Gui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "import pandas as pd\n",
        "\n",
        "# === Your credentials ===\n",
        "api_key_ab = 'nnrtfUtKf6UuIwOsJYvAWV1Bb'\n",
        "api_key_secret_ab = 'maQ4gzLWOwFbqkw4LWdM0YWzAOkIKT5WPDF3Is5cfD1a2fmz1R'\n",
        "access_token_ab = '1413550362280087553-mzUdRr4VyhgFMUiNzlE13CeSduluz9'\n",
        "access_token_secret_ab = 'mhyh7fKm5xmVoIYgCx5kRf3WEoISUQMfRrxCkyp0RvPIo'\n",
        "\n",
        "#  New bearer token\n",
        "bearer_token_ab = 'AAAAAAAAAAAAAAAAAAAAADr74QEAAAAASb997pEXfVpuCGAxkHE56W75t08%3Db1ontiSvc3YWiGhAP6EsGoaecrwYP5pjYJOAAu75iFxHJ8TrzS'\n",
        "\n",
        "# OAuth 1 for legacy support\n",
        "auth_ab = tweepy.OAuth1UserHandler(\n",
        "    consumer_key=api_key_ab,\n",
        "    consumer_secret=api_key_secret_ab,\n",
        "    access_token=access_token_ab,\n",
        "    access_token_secret=access_token_secret_ab\n",
        ")\n",
        "api_ab = tweepy.API(auth_ab)\n",
        "\n",
        "# v2 client\n",
        "client_ab = tweepy.Client(bearer_token=bearer_token_ab, wait_on_rate_limit=True)\n",
        "\n",
        "# Assignment: target hashtags (only 1 request, max 100 tweets)\n",
        "query_ab = '(#machinelearning OR #artificialintelligence OR #generativeAI) -is:retweet lang:en'\n",
        "resp_ab = client_ab.search_recent_tweets(\n",
        "    query=query_ab,\n",
        "    max_results=100,\n",
        "    tweet_fields=[\"created_at\", \"text\", \"author_id\"],\n",
        "    expansions=[\"author_id\"],\n",
        "    user_fields=[\"username\"]\n",
        ")\n",
        "\n",
        "# Map author_id -> username\n",
        "user_lookup_ab = {}\n",
        "if resp_ab.includes and \"users\" in resp_ab.includes:\n",
        "    for u in resp_ab.includes[\"users\"]:\n",
        "        user_lookup_ab[str(u.id)] = u.username\n",
        "\n",
        "# Store required fields\n",
        "tweetDict_ab = {'tweet_id': [], 'username': [], 'tweet_time': [], 'tweetText': []}\n",
        "if resp_ab.data:\n",
        "    for t in resp_ab.data:\n",
        "        tweetDict_ab['tweet_id'].append(t.id)\n",
        "        tweetDict_ab['username'].append(user_lookup_ab.get(str(t.author_id), \"\"))\n",
        "        tweetDict_ab['tweet_time'].append(t.created_at)\n",
        "        tweetDict_ab['tweetText'].append(t.text)\n",
        "\n",
        "# DataFrame\n",
        "dfTweets_ab = pd.DataFrame(tweetDict_ab)\n",
        "print(dfTweets_ab.head())\n",
        "\n",
        "# Save raw\n",
        "dfTweets_ab.to_csv(\"Generative_AI_Tweets_ab.csv\", index=False)\n",
        "print(f\"Saved {len(dfTweets_ab)} rows to Generative_AI_Tweets_ab.csv\")\n"
      ],
      "metadata": {
        "id": "qYRO5Cn8bYwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4224c99b-9d10-4186-87e2-1edbe3aa1d8c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              tweet_id        username                tweet_time  \\\n",
            "0  1972900178131898867  NexusLinkIndia 2025-09-30 05:43:51+00:00   \n",
            "1  1972899833297224046    AmarMohanJha 2025-09-30 05:42:29+00:00   \n",
            "2  1972899726078149050     SteveKlinko 2025-09-30 05:42:04+00:00   \n",
            "3  1972899506179145860         monjere 2025-09-30 05:41:11+00:00   \n",
            "4  1972898594391794078   sakshibhavita 2025-09-30 05:37:34+00:00   \n",
            "\n",
            "                                           tweetText  \n",
            "0  Machine Learning is transforming the way busin...  \n",
            "1  I'm committed to growing my career in AI/ML, b...  \n",
            "2  Please go visit: https://t.co/b27KFRj08m (Musi...  \n",
            "3  It is #AI.\\n\\nIt is not real.\\n\\nLooks real to...  \n",
            "4  Job Opportunity at FACE Prep | Salary Rs 6.0 L...  \n",
            "Saved 100 rows to Generative_AI_Tweets_ab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk, re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "df_Tweet_ab = pd.read_csv('Generative_AI_Tweets_ab.csv')\n",
        "\n",
        "# NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "lemmatizer_ab = WordNetLemmatizer()\n",
        "stop_words_ab = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text_1_ab(text_ab):\n",
        "    if not isinstance(text_ab, str):\n",
        "        text_ab = str(text_ab)\n",
        "    text_ab = text_ab.lower()\n",
        "    text_ab = re.sub(r'http\\S+|www\\.\\S+', ' ', text_ab)   # URLs\n",
        "    text_ab = re.sub(r'[@#]\\w+', ' ', text_ab)            # @handles, #hashtags\n",
        "    text_ab = re.sub(r'[^a-zA-Z\\s]', ' ', text_ab)        # keep letters only\n",
        "    text_ab = re.sub(r'\\s+', ' ', text_ab).strip()\n",
        "    toks_ab = word_tokenize(text_ab)\n",
        "    toks_ab = [w for w in toks_ab if w not in stop_words_ab]\n",
        "    toks_ab = [lemmatizer_ab.lemmatize(w) for w in toks_ab]\n",
        "    return ' '.join(toks_ab)\n",
        "\n",
        "# Clean tweets\n",
        "df_Tweet_ab['tweetText'] = df_Tweet_ab['tweetText'].apply(preprocess_text_1_ab)\n",
        "\n",
        "# Data quality: missing values + duplicates\n",
        "missing_data_ab = df_Tweet_ab.isnull().sum()\n",
        "before_ab = len(df_Tweet_ab)\n",
        "df_Tweet_ab = df_Tweet_ab.drop_duplicates(subset=['tweet_id'])\n",
        "df_Tweet_ab = df_Tweet_ab.drop_duplicates(subset=['username', 'tweetText'])\n",
        "after_ab = len(df_Tweet_ab)\n",
        "\n",
        "if missing_data_ab.any():\n",
        "    print(\"There is missing data; filling defaults.\")\n",
        "    df_Tweet_ab = df_Tweet_ab.fillna('unknown')\n",
        "else:\n",
        "    print(\"No missing data.\")\n",
        "\n",
        "# Save cleaned\n",
        "df_Tweet_ab.to_csv('cleaned_Generative_AI_Tweets_ab.csv', index=False)\n",
        "print(f\"Cleaned rows: {after_ab} (from {before_ab}). Saved to cleaned_Generative_AI_Tweets_ab.csv\")\n",
        "print(\"\\nCleaned Data Sample:\")\n",
        "print(df_Tweet_ab.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrxGeIX9F52E",
        "outputId": "a4bec9a3-bbf5-4f52-c684-41d2663c4d86"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing data.\n",
            "Cleaned rows: 97 (from 100). Saved to cleaned_Generative_AI_Tweets_ab.csv\n",
            "\n",
            "Cleaned Data Sample:\n",
            "              tweet_id        username                 tweet_time  \\\n",
            "0  1972900178131898867  NexusLinkIndia  2025-09-30 05:43:51+00:00   \n",
            "1  1972899833297224046    AmarMohanJha  2025-09-30 05:42:29+00:00   \n",
            "2  1972899726078149050     SteveKlinko  2025-09-30 05:42:04+00:00   \n",
            "3  1972899506179145860         monjere  2025-09-30 05:41:11+00:00   \n",
            "4  1972898594391794078   sakshibhavita  2025-09-30 05:37:34+00:00   \n",
            "\n",
            "                                           tweetText  \n",
            "0  machine learning transforming way business ope...  \n",
            "1  committed growing career ai ml finding right l...  \n",
            "2  please go visit music video find understanding...  \n",
            "3  real look real told using would know introduci...  \n",
            "4             job opportunity face prep salary r lpa  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think this assignment was useful because it taught me how to collect, clean, and analyze real text data. The most difficult part was getting the scraping and API setup to work properly, since small errors could stop the code from running. I enjoyed the text cleaning part, where I could clearly see messy text turn into clean data that was easier to work with. The time given for the assignment was enough, and I was able to finish it step by step without feeling rushed. Overall, it gave me good practice with real-world data tasks."
      ],
      "metadata": {
        "id": "_o1kzwpZKH0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write your response below\n",
        "Fill out survey and provide your valuable feedback.\n",
        "\n",
        "https://docs.google.com/forms/d/e/1FAIpQLSd_ObuA3iNoL7Az_C-2NOfHodfKCfDzHZtGRfIker6WyZqTtA/viewform?usp=dialog"
      ],
      "metadata": {
        "id": "JbTa-jDS-KFI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}